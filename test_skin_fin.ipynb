{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131.37560000000002, 150.4111, 202.9452, 0.0)\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "import imutils\n",
    "from PIL import Image\n",
    "import face_recognition\n",
    "\n",
    "def crop(image):\n",
    "    image = face_recognition.load_image_file(image)\n",
    "    face_locations = face_recognition.face_locations(image)\n",
    "    for face_location in face_locations:\n",
    "        top, right, bottom, left = face_location\n",
    "        face_image = image[top:bottom, left:right]\n",
    "        pil_image = Image.fromarray(face_image)\n",
    "        pil_image.save('image/test/crop.png')\n",
    "\n",
    "        \n",
    "def avg(image):\n",
    "    avg = cv2.mean(image)\n",
    "    print(avg)\n",
    "    rec = np.zeros((500, 500,3), np.uint8)\n",
    "    rec = cv2.rectangle(rec, (0, 0), (500, 500), avg, -1)\n",
    "    cv2.imwrite(\"image/test/skin_color.png\", rec)\n",
    "\n",
    "    \n",
    "def cheek(image):\n",
    "    CHEEK_IDXS = OrderedDict([(\"right_cheek\", (12,14,47,35))])\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    img = cv2.imread(image)\n",
    "    img = imutils.resize(img, width=500)\n",
    "    overlay = img.copy()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    detections = detector(gray, 0)\n",
    "    \n",
    "    for k,d in enumerate(detections):\n",
    "        shape = predictor(gray, d)\n",
    "        pts = np.zeros((len(CHEEK_IDXS['right_cheek']), 2), np.int32)\n",
    "        \n",
    "        for i,j in enumerate(CHEEK_IDXS['right_cheek']):\n",
    "            pts[i] = [shape.part(j).x, shape.part(j).y] \n",
    "            \n",
    "        aa = np.array(pts)\n",
    "        pts = pts.reshape((-1, 1, 2))\n",
    "        rect = cv2.boundingRect(aa)\n",
    "        x, y, w, h = rect\n",
    "        croped = img[y:y + h, x:x + w].copy()\n",
    "        aa = aa - aa.min(axis=0)\n",
    "        mask = np.zeros(croped.shape[:2], np.uint8)\n",
    "        cv2.drawContours(mask, [aa], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "        dst = cv2.bitwise_and(croped, croped, mask=mask)\n",
    "        dst = imutils.resize(dst, width=600)\n",
    "        cv2.imwrite(\"image/test/dst.png\", dst)\n",
    "\n",
    "\n",
    "def center(image):\n",
    "    image = Image.open(image)\n",
    "    width = 500\n",
    "    height = 500\n",
    "    left = (width - 100)/2\n",
    "    top = (height - 100)/2\n",
    "    right = (width + 100)/2\n",
    "    bottom = (height + 100)/2\n",
    "    image = image.crop((left, top, right, bottom))\n",
    "    image.save('image/test/center.png')\n",
    "\n",
    "\n",
    "crop('image/yoon.jpg')\n",
    "cheek('image/test/crop.png')\n",
    "center('image/test/dst.png')\n",
    "face_color = cv2.imread('image/test/center.png')\n",
    "avg(face_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
